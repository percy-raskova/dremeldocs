# DremelDocs Project Index

## ğŸ“š Project Overview
**Name**: DremelDocs (formerly AstraDocs)
**Purpose**: Transform Twitter/X archive into curated philosophical/political knowledge base
**Status**: 85% complete (awaiting manual theme extraction)
**Stack**: Python 3.12, MkDocs Material, SpaCy, uv

---

## ğŸ—‚ï¸ Directory Structure

```
dremeldocs/
â”œâ”€â”€ ğŸ“ scripts/                    # Core processing pipeline
â”œâ”€â”€ ğŸ“ tests/                      # Test suite (119 tests)
â”œâ”€â”€ ğŸ“ docs/                       # Documentation & content
â”œâ”€â”€ ğŸ“ data/                       # Working data directory
â”œâ”€â”€ ğŸ“ markdown/                   # MkDocs website content
â”œâ”€â”€ ğŸ“ config/                     # Configuration files
â”œâ”€â”€ ğŸ“ .serena/                    # Serena MCP project
â”œâ”€â”€ ğŸ“ .notes/                     # Historical/ephemeral docs
â”œâ”€â”€ ğŸ“ twitter-archives/           # Source Twitter data
â””â”€â”€ ğŸ“„ Core Files                  # Project configuration
```

---

## ğŸ”§ Core Scripts

### Main Pipeline Components

| Script | Purpose | Status | Location |
|--------|---------|--------|----------|
| `local_filter_pipeline.py` | Stream JSON processing, thread extraction | âœ… Complete | scripts/ |
| `generate_heavy_hitters.py` | Generate markdown for 500+ word threads | âœ… Complete | scripts/ |
| `theme_classifier.py` | Classify threads by user-defined themes | â³ Awaiting themes | scripts/ |
| `text_processing.py` | NLP utilities with SpaCy integration | âœ… Complete | scripts/ |

### Testing & Development Scripts

| Script | Purpose | Location |
|--------|---------|----------|
| `test_enhanced_extraction.py` | Test NLP tag extraction | scripts/ |
| `test_filename_generation.py` | Validate filename generation | scripts/ |
| `test_transformer_power.py` | Transformer model testing | scripts/ |

---

## ğŸ“– Documentation

### Core Documentation

| Document | Description | Path |
|----------|-------------|------|
| `PROJECT_INDEX.md` | This file - comprehensive navigation | Root |
| `README.md` | Project overview and quick start | Root |
| `CLAUDE.md` | Instructions for Claude Code | Root |
| `PROJECT_KNOWLEDGE_BASE` | Serena memory - complete reference | .serena/memories/ |

### Technical Documentation

| Document | Purpose | Location |
|----------|---------|----------|
| `INDEX.md` | Documentation navigation | docs/ |
| `ARCHITECTURE.md` | System design and flow | docs/ |
| `API.md` | Script API reference | docs/ |
| `STATUS.md` | Current project status | docs/ |
| `workflow.md` | Development workflow | docs/ |
| `setup.md` | Environment setup | docs/ |
| `testing.md` | Testing framework | docs/ |

### Heavy Hitters Content

**Location**: `docs/heavy_hitters/`
**Count**: 59 markdown files
**Total Words**: 42,774
**Purpose**: Long-form philosophical/political threads for manual theme extraction

Key files:
- `index.md` - Navigation for all heavy hitters
- `THEME_TEMPLATE.md` - Template for user theme extraction
- Individual threads: `001-*.md` through `059-*.md`

---

## ğŸ§ª Test Suite

### Structure
```
tests/
â”œâ”€â”€ unit/                  # Unit tests (98 tests)
â”‚   â”œâ”€â”€ test_text_processing.py
â”‚   â”œâ”€â”€ test_generate_heavy_hitters.py
â”‚   â””â”€â”€ test_frontmatter_generation.py
â”œâ”€â”€ integration/           # Integration tests (21 tests)
â”‚   â”œâ”€â”€ test_filter_pipeline.py
â”‚   â””â”€â”€ test_end_to_end.py
â”œâ”€â”€ fixtures/             # Test data and utilities
â”‚   â””â”€â”€ sample_data.py
â””â”€â”€ conftest.py          # pytest configuration
```

**Coverage**: 89% on core modules
**Status**: 119/119 tests passing (100%)
**Command**: `uv run pytest tests/ --cov=scripts`

---

## ğŸ’¾ Data Flow

### Input â†’ Processing â†’ Output

```mermaid
graph LR
    A[twitter-archives/data/tweets.js<br/>37MB, 21,723 tweets] -->
    B[local_filter_pipeline.py<br/>Stream processing]
    B --> C[data/filtered_threads.json<br/>1,363 threads]
    C --> D[generate_heavy_hitters.py<br/>Extract long threads]
    D --> E[docs/heavy_hitters/<br/>59 files, 42,774 words]
    E --> F[Manual Theme Extraction<br/>USER ACTION REQUIRED]
    F --> G[theme_classifier.py<br/>Classify all threads]
    G --> H[markdown/<br/>Final MkDocs site]
```

---

## ğŸ¨ Website Structure

### MkDocs Configuration
**Location**: `mkdocs.yml`
**Theme**: Material with custom CSS
**Features**: Dark mode, responsive, metadata cards

### Content Organization
```
markdown/
â”œâ”€â”€ index.md              # Homepage with dedication
â”œâ”€â”€ about/                # AI collaboration page
â”‚   â””â”€â”€ ai-ethics.md     # Leftist perspective on AI
â”œâ”€â”€ themes/               # Organized by classification
â”‚   â”œâ”€â”€ philosophy/       # Philosophical threads
â”‚   â”œâ”€â”€ politics/         # Political analysis
â”‚   â””â”€â”€ science/          # Scientific discussions
â””â”€â”€ stylesheets/          # Custom CSS
    â””â”€â”€ extra.css        # Courier Prime font, earthy colors
```

---

## ğŸ”„ Workflow Pipeline

### Current State
1. âœ… **Data Extraction**: Complete
2. âœ… **Filtering**: 21,723 â†’ 1,363 threads
3. âœ… **Heavy Hitters**: 59 generated
4. â³ **Theme Extraction**: BLOCKED - User action required
5. â³ **Classification**: Ready to run
6. â³ **Site Generation**: Ready to build

### Commands for Each Stage
```bash
# 1. Extract and filter
uv run python scripts/local_filter_pipeline.py

# 2. Generate heavy hitters
uv run python scripts/generate_heavy_hitters.py

# 3. [USER ACTION] Review docs/heavy_hitters/
# Fill out THEME_TEMPLATE.md â†’ THEMES_EXTRACTED.md

# 4. Classify all threads
uv run python scripts/theme_classifier.py

# 5. Serve website locally
mkdocs serve

# 6. Build for deployment
mkdocs build
```

---

## ğŸ› ï¸ Configuration

### Python Dependencies
**File**: `pyproject.toml`
**Manager**: uv
**Key packages**:
- pandas, ijson (data processing)
- spacy, en_core_web_lg (NLP)
- mkdocs, mkdocs-material (documentation)
- anthropic, openai (AI classification)
- click, loguru, tqdm (utilities)

### NLP Configuration
**Model**: SpaCy en_core_web_lg
**Config**: `config/nlp_settings.yaml`
**Domain vocabulary**: 70+ political/philosophical terms
**Installation**:
```bash
uv pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl
```

### Git Configuration
- Feature branches only
- Conventional commits
- Pre-commit hooks installed
- `.gitignore` configured

---

## ğŸ“Š Project Metrics

### Performance
- **Processing Time**: ~2 minutes for full pipeline
- **Memory Usage**: 50MB peak
- **Cost Savings**: $108 (avoided API calls)
- **Reduction Rate**: 96% (21,723 â†’ 1,363 threads)

### Content Statistics
- **Total Tweets**: 21,723
- **Filtered Threads**: 1,363
- **Heavy Hitters**: 59 (500+ words each)
- **Total Content**: 42,774 words of philosophy/politics

### Code Quality
- **Test Coverage**: 89% on core modules
- **Test Pass Rate**: 100% (119/119)
- **Lines of Code**: ~2,500
- **Documentation**: Comprehensive

---

## ğŸ”— Cross-References

### Related Documentation
- Technical details â†’ [`ARCHITECTURE.md`](docs/ARCHITECTURE.md)
- API reference â†’ [`API.md`](docs/API.md)
- Current status â†’ [`STATUS.md`](docs/STATUS.md)
- Testing guide â†’ [`testing.md`](docs/testing.md)
- Setup instructions â†’ [`setup.md`](docs/setup.md)

### Key Memories (Serena)
- Complete reference â†’ `PROJECT_KNOWLEDGE_BASE`
- SpaCy/uv insights â†’ `technical_learnings_spacy_uv`
- NLP setup â†’ `project_nlp_infrastructure`
- Quick commands â†’ `suggested_commands`

### Session History
- Development timeline â†’ `.notes/session_history/`
- Cleanup summary â†’ `.notes/CLEANUP_SUMMARY.md`
- Best practices â†’ `.notes/SERENA_MEMORY_BEST_PRACTICES.md`

---

## ğŸš€ Quick Start

```bash
# Clone and setup
cd /home/percy/projects/dremeldocs
uv pip install -r requirements.txt

# Run tests
uv run pytest tests/

# Process data
uv run python scripts/local_filter_pipeline.py
uv run python scripts/generate_heavy_hitters.py

# Review heavy hitters
ls docs/heavy_hitters/*.md

# [MANUAL STEP] Extract themes
# Edit THEME_TEMPLATE.md â†’ THEMES_EXTRACTED.md

# Complete processing
uv run python scripts/theme_classifier.py

# Preview site
mkdocs serve
```

---

## ğŸ“ Notes

- Project is 85% complete, blocked on manual theme extraction
- All infrastructure ready for final processing
- Estimated 1-2 hours user work + 20 minutes automated processing
- Website design complete with romantic dedication to Meredith

---

*Generated: 2025-01-23 | DremelDocs Project Index v1.0*