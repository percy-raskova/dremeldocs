---
title: "fit in the context"
date: Tue Nov 26
description: "This is, ironically, the *worst* use case for chatgpt, which excels at stringing sentences together -- but whose only criteria for those sentences is that they..."
thread_id: thread_0253
word_count: 179
reading_time: 1
primary_theme: dialectics
tags: ["dialectics"]
---

# fit in the context

This is, ironically, the *worst* use case for chatgpt, which excels at stringing sentences together -- but whose only criteria for those sentences is that they "fit in the context." It has no conception of truthfulness, and quite often just makes up facts that "sound right." https://t.co/eWGiG2CWwk If you ask it about a certain Japanese emperor in 1657, chatgpt might tell you in great detail about his brother who never existed, his effort to pacify a rebellion that never happened, etc. And it would phrase it with such confidence that you wouldn't even think to double check. It's trawling vast amounts of text, not for *factual* information, but for *linguistic* information. It doesn't ask itself "What do sources say about [X Japanese emperor]?" but rather "How might someone *phrase things* when talking about [X Japanese emperor]?" The ability to draw on and synthesis large quantities of factual information is not beyond the capabilities of AI (assuming it's given cues for how to assess the quality of that information), but that's simply not what chat bots are designed to do.